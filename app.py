import streamlit as st
import os
import json
import time
from auditor_qwen import VideoAuditor, TRAINPAL_RULES
from datetime import datetime

# --- Cost Governance Helpers ---
COST_LOG_FILE = "cost_history.json"

def load_history():
    if not os.path.exists(COST_LOG_FILE):
        return []
    try:
        with open(COST_LOG_FILE, "r") as f:
            return json.load(f)
    except:
        return []

def append_history(model_name, cost, video_name):
    history = load_history()
    if len(history) > 100: history = history[-100:] # Keep last 100
    
    record = {
        "date": datetime.now().strftime("%Y-%m-%d"),
        "time": datetime.now().strftime("%H:%M:%S"),
        "model": model_name.split("(")[0].strip(),
        "cost": float(f"{cost:.4f}"),
        "video": video_name if video_name else "Upload"
    }
    history.append(record)
    with open(COST_LOG_FILE, "w") as f:
        json.dump(history, f, indent=2, ensure_ascii=False)


# Page Config
st.set_page_config(
    page_title="TrainPal AdGuard (Qwen-VL Edition)",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for "AdGuard" Vibe
st.markdown("""
<style>
    .report-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #ff4b4b;
        margin-bottom: 20px;
    }
    .pass-card {
        border-left: 5px solid #00cc66;
    }
    .metric-box {
        text-align: center;
        padding: 10px;
        background: #ffffff;
        border-radius: 8px;
        border: 1px solid #e0e0e0;
    }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# Sidebar: Setup & Upload
# -----------------------------------------------------------------------------
with st.sidebar:
    st.image("https://img.alicdn.com/tfs/TB1.M6cWwHqK1RjSZFgXXa7JXXa-200-200.png", width=60) # Qwen Logo placeholder
    st.title("TrainPal å®¡æ ¸ç›¾")
    
    # --- Model Selection (New) ---
    # --- Model Selection (New) ---
    st.markdown("### ğŸ§  æ¨¡å‹é…ç½® (Model)")
    model_type = st.selectbox(
        "åŸºç¡€æ¨¡å‹é€‰æ‹© (2026 Vision Model Matrix)", 
        [
            "Qwen-VL-Max (Alibaba Flagship)",
            "Qwen2.5-VL-7B (Alibaba Efficient)",
            "DeepSeek-VL2-Pro (DeepSeek Flagship)",
            "DeepSeek-VL2-Small (DeepSeek Efficient)",
            "GPT-5-Vision (OpenAI Flagship)",
            "GPT-4o-mini (OpenAI Efficient)",
            "Gemini 3.0 Pro (Google Flagship)",
            "Gemini 3.0 Flash (Google Efficient)",
            "MiniMax-abab7 (MiniMax Flagship)",
            "MiniMax-VL-Flash (MiniMax Efficient)"
        ],
        index=0, # Default to Qwen-VL-Max
        help="æ¯ä¸ªç³»åˆ—ç²¾é€‰ï¼šä¸€æ¬¾æœ€å¼ºæ——èˆ° (Flagship) + ä¸€æ¬¾é«˜æ€§ä»·æ¯” (Efficient)"
    )
    
    # Map UI names to real API model IDs (2026 Standards)
    MODEL_MAP = {
        "Qwen-VL-Max": "qwen-vl-max",
        "Qwen2.5-VL-7B": "qwen2.5-vl-7b-instruct",
        "DeepSeek-VL2-Pro": "deepseek-vl2-pro",
        "DeepSeek-VL2-Small": "deepseek-vl2-small",
        "GPT-5-Vision": "gpt-5-vision-preview",
        "GPT-4o-mini": "gpt-4o-mini",
        "Gemini 3.0 Pro": "gemini-3.0-pro-001",
        "Gemini 3.0 Flash": "gemini-3.0-flash-001",
        "MiniMax-abab7": "abab7-chat",
        "MiniMax-VL-Flash": "abab6.5s-chat"
    }
    
    # Find closest match in map
    real_model_id = "qwen-vl-max"
    for k, v in MODEL_MAP.items():
        if k in model_type:
            real_model_id = v
            break
            
    model_config = {}
    
    # Auto-configure API endpoints
    if "Qwen" in model_type:
        st.caption(f"Powered by **Aliyun DashScope ({real_model_id})**")
        api_key = st.text_input("DashScope API Key", type="password")
        
        model_config = {
            "type": "qwen",
            "model_name": real_model_id,
            "api_key": api_key
        }
    else:
        # Generic Configuration
        st.caption(f"Configuring **{real_model_id}** Endpoint")
        
        default_base = "https://api.openai.com/v1"
        if "DeepSeek" in model_type: default_base = "https://api.deepseek.com"
        if "MiniMax" in model_type: default_base = "https://api.minimax.chat/v1"
        if "Gemini" in model_type: default_base = "https://generativelanguage.googleapis.com/v1beta/openai"

        base_url = st.text_input("API Base URL", value=default_base)
        api_key = st.text_input("API Key", type="password")
        model_config = {
            "type": "openai_compatible",
            "model_name": real_model_id, 
            "api_key": api_key,
            "base_url": base_url
        }
        
    if not api_key:
        st.warning("è¯·é…ç½® API Key ä»¥ç»§ç»­")
        
    st.divider()
    st.markdown("### ğŸ“‹ å®¡æ ¸è§„åˆ™ (Rules)")
    st.caption("åŸºäº TrainPal å®˜æ–¹å®¡æ ¸æ ‡å‡† (12æ¡çº¢çº¿)")
    
    # Simple list instead of dataframe for better look
    with st.expander("æŸ¥çœ‹ 12 æ¡çº¢çº¿åˆ—è¡¨"):
         st.markdown("""
         1. ç«å“ä¸å“ç‰Œå…³ç³»
         2. ä»·æ ¼ä¸ä¼˜æƒ åˆè§„
         3. æ”¿æ²»ä¸æ•æ„Ÿå†…å®¹
         4. å†…å®¹çœŸå®æ€§
         5. å¹¿å‘Šèº«ä»½æŠ«éœ²
         6. è‚–åƒæƒä¸éšç§ (GDPR)
         7. è¿æ³•ä¸æš´åŠ›å†…å®¹
         8. è‰²æƒ…ä½ä¿—
         9. æœªæˆå¹´äººä¿æŠ¤
         10. ç¦æ­¢æŠ¹é»‘é“è·¯
         11. ä¾›åº”å•†çº¢çº¿
         12. é£é™©ç”»é¢ç´ æ
         """)
    
    # --- Cost Admin Dashboard ---
    st.divider()
    st.markdown("### ğŸ“Š æˆæœ¬çœ‹æ¿ (Cost Admin)")
    
    # Load history
    history = load_history()
    today_str = datetime.now().strftime("%Y-%m-%d")
    today_cost = sum(item['cost'] for item in history if item['date'] == today_str)
    
    st.metric("ğŸ“… ä»Šæ—¥æ€»æ¶ˆè€— (Today)", f"Â¥ {today_cost:.4f}")
    
    with st.expander("ğŸ•’ æ¶ˆè´¹æ˜ç»† (Records)", expanded=False):
        if history:
            # Show simplified table
            st.dataframe(
                history[::-1][:10], # Last 10 reversed
                column_order=["time", "model", "cost"], 
                column_config={
                    "time": "æ—¶é—´",
                    "model": "æ¨¡å‹",
                    "cost": st.column_config.NumberColumn("è´¹ç”¨ (Â¥)", format="%.4f")
                },
                hide_index=True
            )
        else:
            st.caption("æš‚æ— è®°å½•")

# -----------------------------------------------------------------------------
# Main Area
# -----------------------------------------------------------------------------
st.title("ğŸ›¡ï¸ è§†é¢‘åˆè§„è‡ªåŠ¨åŒ–å®¡æ ¸ (Demo)")

col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("1. è§†é¢‘ä¸Šä¼ ")
    uploaded_file = st.file_uploader("æ‹–æ‹½æˆ–ç‚¹å‡»ä¸Šä¼  (.mp4, .mov, .avi)", type=["mp4", "mpeg4", "mov", "avi", "mkv"])
    
    if uploaded_file:
        # Save temp
        video_path = f"temp_upload_{int(time.time())}.mp4"
        with open(video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.video(video_path)
        
        # Auditor Instance
        if api_key:
            # Model Connection Tip
            if model_config.get('type') != 'qwen':
                m_name = model_config.get('model_name', '')
                m_lower = m_name.lower()
                if "deepseek" in m_lower or "minimax" in m_lower or "yi" in m_lower or "doubao" in m_lower or "qwen" in m_lower:
                    st.success(f"âœ… **{m_name}** ä¸ºå›½äº§æ¨¡å‹ï¼ŒæœåŠ¡å™¨ä½äºå›½å†…ï¼Œæ”¯æŒé«˜é€Ÿç›´è¿ã€‚")
                else:
                    st.warning(f"âš ï¸ **{m_name}** æœåŠ¡å™¨ä½äºæµ·å¤–ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç½‘ç»œç¯å¢ƒå·²é…ç½®å›½é™…åŠ é€ŸèŠ‚ç‚¹ï¼Œå¦åˆ™å¯èƒ½è¶…æ—¶ã€‚")

            if st.button("ğŸš€ å¼€å§‹ AI æ™ºèƒ½å®¡æ ¸ (Start Audit)", type="primary"):
                # Use a status container
                status = st.status("ğŸ” AI æ­£åœ¨ä»‹å…¥å®¡æ ¸...", expanded=True)
                
                try:
                    # Init auditor
                    # For non-qwen, we pass the key but the internal Qwen SDK won't be used until audit_video()
                    auditor = VideoAuditor(api_key) 
                    
                    # Step 1: Video -> Images (Universal)
                    status.write("ğŸ“¸ æ­£åœ¨æå–å…³é”®å¸§ (Adaptive Sampling)...")
                    frames = auditor.extract_keyframes(video_path)
                    status.write(f"âœ… æå–å®Œæˆ: {len(frames)} å¼ å…³é”®ç”»é¢")
                    
                    # Show thumbnails
                    st.write("---")
                    st.caption("ğŸ“¸ å…³é”®å¸§é¢„è§ˆ (Keyframes Preview)")
                    if frames:
                        cols = st.columns(min(len(frames), 5))
                        for idx, (t, p) in enumerate(frames):
                             cols[idx % 5].image(p, caption=f"{t}s", use_container_width=True)
                    
                    # Step 2: Audio -> Text (Universal - Whisper Local)
                    status.write("ğŸ¤ æ­£åœ¨è¿›è¡Œè¯­éŸ³è½¬å†™ (Whisper Local)...")
                    
                    transcript = auditor.extract_audio(video_path)
                    st.text_area("è¯­éŸ³æ–‡æœ¬ (Transcript)", transcript, height=100)
                except Exception as e:
                    st.error(f"Whisper Error: {e}")
                    transcript = ""
                
                # Step 3: LLM Inference
                display_name = model_config.get('model_name', 'AI Model').split('(')[0].strip()
                status.write(f"ğŸ§  {display_name} æ­£åœ¨è¿›è¡Œå¤šæ¨¡æ€è”åˆåˆ†æ...")
                raw_result = auditor.audit(frames, transcript, model_config=model_config)
                
                status.update(label="âœ… å®¡æ ¸å®Œæˆ!", state="complete", expanded=False)

            
            # -----------------------------------------------------------------------------
            # Report Display (Redesigned)
            # -----------------------------------------------------------------------------
            st.divider()
            with col2:
                st.subheader("2. å®¡æ ¸æŠ¥å‘Š (Audit Report)")
                
                if 'raw_result' not in locals():
                    st.info("ğŸ‘‹ å‡†å¤‡å°±ç»ªã€‚è¯·ç‚¹å‡» **'ğŸš€ å¼€å§‹ AI æ™ºèƒ½å®¡æ ¸'** æŒ‰é’®ä»¥å¯åŠ¨ DeepSeek/Qwen è¿›è¡Œå¤šæ¨¡æ€åˆ†æã€‚")
                    st.stop()
                
                try:
                    # Parse result
                    clean_json = raw_result.replace("```json", "").replace("```", "").strip()
                    res = json.loads(clean_json)
                    
                    status_result = res.get("audit_result", "WARNING")
                    score = res.get("risk_score", 0)
                    violations = res.get("violations", [])
                    
                    # Helper function to find matching frame (improved)
                    import re
                    def find_frame_for_violation(timestamp_str, frames_list):
                        try:
                            matches = re.findall(r"[-+]?\d*\.\d+|\d+", timestamp_str)
                            if not matches: return None, None
                            v_t = float(matches[0])
                            
                            # Find the CLOSEST frame within tolerance
                            best_match = None
                            min_diff = float('inf')
                            tolerance = 0.9  # Tighter tolerance (was 1.5s)
                            
                            for t, p in frames_list:
                                diff = abs(t - v_t)
                                if diff < tolerance and diff < min_diff:
                                    min_diff = diff
                                    best_match = (p, t)
                            
                            if best_match:
                                return best_match[0], best_match[1]  # (path, actual_time)
                        except:
                            pass
                        return None, None
                    
                    # === Merge consecutive violations into ranges ===
                    def merge_violations(violations_list, frames_list):
                        """
                        Merge consecutive violations of the same category into time ranges.
                        Returns: list of merged violations with format:
                        {
                            'category': str,
                            'reason': str,
                            'time_range': '3.2s - 8.0s' or '3.2s' (single),
                            'frames': [(time, path), ...],  # Representative frames
                            'count': int  # Number of original violations merged
                        }
                        """
                        if not violations_list:
                            return []
                        
                        # Group by category + reason (same type of violation)
                        from collections import defaultdict
                        groups = defaultdict(list)
                        
                        for v in violations_list:
                            cat = v.get('category', 'æœªåˆ†ç±»')
                            reason = v.get('reason', 'æ— è¯¦ç»†è¯´æ˜')
                            timestamp_str = v.get('timestamp', '0')
                            
                            # Extract numeric time
                            try:
                                matches = re.findall(r"[-+]?\d*\.\d+|\d+", timestamp_str)
                                if matches:
                                    time_val = float(matches[0])
                                    # Group by category (not reason, to merge similar violations)
                                    groups[cat].append({
                                        'time': time_val,
                                        'reason': reason,
                                        'original': v
                                    })
                            except:
                                pass
                        
                        # Merge consecutive violations within each category
                        merged = []
                        merge_threshold = 3.0  # Stricter threshold (3s) to distinguish scenes
                        
                        for cat, items in groups.items():
                            items.sort(key=lambda x: x['time'])
                            
                            i = 0
                            while i < len(items):
                                start_time = items[i]['time']
                                end_time = start_time
                                reasons = set([items[i]['reason']])
                                count = 1
                                
                                # Look ahead
                                j = i + 1
                                while j < len(items):
                                    # Logic: Must be close in time
                                    time_gap = items[j]['time'] - end_time
                                    is_close = time_gap <= merge_threshold
                                    
                                    if not is_close:
                                        break
                                        
                                    end_time = items[j]['time']
                                    reasons.add(items[j]['reason'])
                                    count += 1
                                    j += 1
                                
                                # Describe Reason
                                reasons_list = list(reasons)
                                if len(reasons_list) > 2:
                                    # Show top 2 and ...
                                    main_reason = f"{reasons_list[0]}; {reasons_list[1]}..."
                                else:
                                    main_reason = "; ".join(reasons_list)

                                # Select Representative Frames (Start, Middle, End)
                                target_times = [start_time]
                                if count > 2:
                                    target_times.append((start_time + end_time) / 2)
                                if start_time != end_time:
                                    target_times.append(end_time)
                                
                                selected_frames = []
                                selected_paths = set()
                                
                                for t_target in target_times:
                                    # Find closest frame in frames_list
                                    best_p = None
                                    best_t = 0
                                    min_diff = 1.0 # 1s tolerance
                                    
                                    for ft, fp in frames_list:
                                        diff = abs(ft - t_target)
                                        if diff < min_diff:
                                            min_diff = diff
                                            best_p = fp
                                            best_t = ft
                                    
                                    if best_p and best_p not in selected_paths:
                                        selected_frames.append((best_t, best_p))
                                        selected_paths.add(best_p)

                                merged.append({
                                    "category": cat,
                                    "time_range": f"{start_time}s - {end_time}s" if start_time != end_time else f"{start_time}s",
                                    "reason": main_reason,
                                    "count": count,
                                    "frames": selected_frames
                                })
                                i = j
                        
                        # Sort merged by start time
                        merged.sort(key=lambda x: float(re.findall(r"[\d\.]+", x['time_range'])[0]) if re.findall(r"[\d\.]+", x['time_range']) else 0)
                        
                        return merged
                    
                    # Apply merging
                    merged_violations = merge_violations(violations, frames)
                    
                    # === Audio Audit Status ===
                    st.markdown("### ğŸ¤ éŸ³é¢‘å®¡æ ¸")
                    
                    # Check if transcription failed
                    transcription_failed = ("[Audio Error]" in transcript or "[Whisper Error]" in transcript or transcript == "")
                    
                    if transcription_failed:
                        st.error("âŒ éŸ³é¢‘è½¬å†™å¤±è´¥")
                        st.caption("âš ï¸ éŸ³é¢‘è½¬å†™å¤±è´¥ï¼Œè¯·æ£€æŸ¥è§†é¢‘éŸ³è½¨æˆ–ç½‘ç»œè¿æ¥")
                    else:
                        # Show transcript
                        with st.expander("ğŸ“ æŸ¥çœ‹éŸ³é¢‘è½¬å†™å†…å®¹", expanded=False):
                            st.text_area("è½¬å†™æ–‡æœ¬", transcript, height=100, disabled=True)
                        
                        # Check for audio-specific violations
                        # Only violations that explicitly mention audio/transcript issues
                        audio_violations = [v for v in violations if 
                                          ("æ”¿æ²»" in v.get('category', '') and "é¦™æ¸¯" in v.get('reason', '')) or
                                          ("ä»·æ ¼" in v.get('category', '') and any(word in v.get('reason', '') for word in ["æœ€ä¾¿å®œ", "æœ€ä½", "æœ€ä½³"])) or
                                          ("ä¾›åº”å•†" in v.get('category', '')) or
                                          ("æŠ¹é»‘" in v.get('category', ''))]
                        
                        if audio_violations:
                            st.error(f"âŒ éŸ³é¢‘å†…å®¹å­˜åœ¨è¿è§„ ({len(audio_violations)} é¡¹)")
                            for v in audio_violations:
                                st.markdown(f"â€¢ **{v.get('category')}**: {v.get('reason')}")
                        else:
                            st.success("âœ… éŸ³é¢‘å†…å®¹å®¡æ ¸é€šè¿‡")
                    
                    st.divider()
                    
                    # === Visual Audit Status ===
                    st.markdown("### ğŸ¬ è§†è§‰å®¡æ ¸")
                    
                    if status_result == "PASS":
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                                    padding: 30px; border-radius: 15px; color: white; text-align: center;">
                            <h1 style="margin: 0; font-size: 3em;">âœ…</h1>
                            <h2 style="margin: 10px 0;">å®¡æ ¸é€šè¿‡ (PASS)</h2>
                            <p style="margin: 0; opacity: 0.9;">é£é™©è¯„åˆ†: {score}/100 | æœªå‘ç°æ˜æ˜¾è¿è§„é¡¹</p>
                        </div>
                        """, unsafe_allow_html=True)
                        st.balloons()
                        
                    else:
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); 
                                    padding: 30px; border-radius: 15px; color: white; text-align: center;">
                            <h1 style="margin: 0; font-size: 3em;">âŒ</h1>
                            <h2 style="margin: 10px 0;">é©³å› (FAIL)</h2>
                            <p style="margin: 0; opacity: 0.9;">é£é™©è¯„åˆ†: {score}/100 | å‘ç°ä¸‹åˆ—ç¡¬æ€§çº¢çº¿è¿è§„</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        st.markdown("<br>", unsafe_allow_html=True)
                        
                        # === Violations with Embedded Images ===
                        if merged_violations:
                            st.markdown("### ğŸ›‘ è¿è§„æ˜ç»†ä¸è¯æ®")
                            
                            for idx, mv in enumerate(merged_violations, 1):
                                time_range = mv['time_range']
                                category = mv['category']
                                reason = mv['reason']
                                count = mv['count']
                                rep_frames = mv['frames']
                                
                                # Count badge
                                count_badge = f" <span style='background: #ff6b6b; color: white; padding: 2px 8px; border-radius: 12px; font-size: 0.85em;'>Ã—{count}</span>" if count > 1 else ""
                                
                                # Violation Card
                                st.markdown(f"""
                                <div style="background: #fff3cd; border-left: 5px solid #ff6b6b; 
                                            padding: 15px; border-radius: 10px; margin-bottom: 20px;">
                                    <h4 style="margin: 0 0 10px 0; color: #d63031;">
                                        #{idx} | {category} @ {time_range}{count_badge}
                                    </h4>
                                    <p style="margin: 0; color: #2d3436; font-size: 0.95em;">
                                        <strong>è¿è§„åŸå› :</strong> {reason}
                                    </p>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # Show representative frames
                                if rep_frames:
                                    if len(rep_frames) == 1:
                                        # Single frame
                                        st.image(rep_frames[0][1], caption=f"ğŸ“¸ è¿è§„ç”»é¢ @ {rep_frames[0][0]}s", use_container_width=True)
                                    else:
                                        # Multiple frames in grid
                                        frame_cols = st.columns(min(len(rep_frames), 3))
                                        labels = ["èµ·å§‹", "ä¸­é—´", "ç»“æŸ"] if len(rep_frames) == 3 else ["èµ·å§‹", "ç»“æŸ"]
                                        for i, (t, path) in enumerate(rep_frames):
                                            with frame_cols[i]:
                                                label = labels[i] if i < len(labels) else f"å¸§{i+1}"
                                                st.image(path, caption=f"ğŸ“¸ {label} @ {t}s", use_container_width=True)
                                else:
                                    st.caption("âš ï¸ æœªæ‰¾åˆ°å¯¹åº”ç”»é¢ï¼ˆå¯èƒ½ä¸ºéŸ³é¢‘è¿è§„æˆ–æ—¶é—´æˆ³è¶…å‡ºé‡‡æ ·èŒƒå›´ï¼‰")
                                
                                st.markdown("<br>", unsafe_allow_html=True)
                        else:
                            st.warning("âš ï¸ AI åˆ¤å®šä¸º FAILï¼Œä½†æœªè¿”å›ç»“æ„åŒ–è¿è§„æ˜ç»†ã€‚è¯·æŸ¥çœ‹ä¸‹æ–¹åŸå§‹ç»“æœã€‚")
                    
                    # Raw Result (Collapsible)
                    with st.expander("ğŸ” æŸ¥çœ‹ AI åŸå§‹è¿”å›ç»“æœ (Raw JSON)", expanded=False):
                        st.json(res)
                        st.divider()
                        st.text(raw_result)

                    # Cost Estimation (DataLearner 2026 Real-Time Pricing)
                    st.divider()
                    st.caption("ğŸ’° æˆæœ¬é¢„ä¼° (Cost Estimation)")
                    
                    c1, c2, c3 = st.columns(3)
                    
                    # 1. Estimate Tokens
                    input_tokens = len(frames) * 1000 + len(transcript)
                    output_tokens = 500 # Approx output
                    
                    # 2. Determine Price (Ref: Aliyun Official Screenshot & DataLearner 2026)
                    # Pricing Unit: CNY (Â¥) per 1 Million Tokens
                    PRICING_TABLE = {
                        "Qwen":     {"in": 3.20, "out": 12.80},     # Qwen3-Max (Standard: Â¥0.0032/1K)
                        "Qwen Efficient": {"in": 1.50, "out": 6.00}, # Qwen-VL-Instruct (Approx Â¥0.0015/1K)
                        
                        "DeepSeek": {"in": 1.00, "out": 4.00},      # V3 (Aggressive Pricing)
                        "MiniMax":  {"in": 1.00, "out": 4.00},      # Competitive
                        "Gemini Flash": {"in": 0.70, "out": 2.80},  # Extremely Low Cost
                        
                        "GPT":      {"in": 18.00, "out": 72.00},    # GPT-5 ($2.50/$10.00)
                        "Gemini":   {"in": 10.00, "out": 35.00},    # Gemini Pro ($1.40/$5.00)
                        "Claude":   {"in": 20.00, "out": 100.00},   # Claude Opus
                    }
                    
                    model_key = "GPT" # Default fallback
                    
                    if "Flash" in display_name:
                        if "Gemini" in display_name: model_key = "Gemini Flash"
                        elif "MiniMax" in display_name: model_key = "MiniMax"
                    elif "Efficient" in display_name or "7B" in display_name or "Small" in display_name:
                        if "Qwen" in display_name: model_key = "Qwen Efficient"
                        elif "DeepSeek" in display_name: model_key = "DeepSeek"
                    elif "DeepSeek" in display_name: model_key = "DeepSeek"
                    elif "Qwen" in display_name: model_key = "Qwen"
                    elif "Gemini" in display_name: model_key = "Gemini"
                    elif "MiniMax" in display_name: model_key = "MiniMax"
                    elif "GPT" in display_name: model_key = "GPT"
                    elif "Claude" in display_name: model_key = "Claude"
                            
                    price_in = PRICING_TABLE.get(model_key, {"in": 18.0, "out": 72.0})["in"]
                    price_out = PRICING_TABLE.get(model_key, {"in": 18.0, "out": 72.0})["out"]
                    
                    # 3. Calculate (Direct RMB)
                    input_cost = (input_tokens / 1_000_000) * price_in
                    output_cost = (output_tokens / 1_000_000) * price_out
                    cost_est = input_cost + output_cost
                    
                    c1.metric("Token æ¶ˆè€—", f"~{input_tokens/1000:.1f}k")
                    c2.metric("é¢„ä¼°è´¹ç”¨", f"Â¥ {cost_est:.4f}", help=f"åŸºäº {model_key} å®˜æ–¹å®šä»·: Â¥{price_in}/1M Input, Â¥{price_out}/1M Output")
                    c3.metric("æ¨¡å‹", display_name)
                    
                    st.caption(f"Pricing Source: Aliyun Official (2026-02) & DataLearner. Unit: RMB/1M Tokens.")
                    
                    # Log to History (Safe Wrapper)
                    try:
                        v_name = uploaded_video.name if uploaded_video else "Captured Video"
                        append_history(display_name, cost_est, v_name)
                        # Optional: st.toast("âœ… æˆæœ¬å·²è®¡å…¥çœ‹æ¿")
                    except Exception as log_e:
                        print(f"Error logging cost: {log_e}")
                        st.error(f"æ—¥å¿—è®°å½•å¤±è´¥: {str(log_e)}")

                except Exception as e:
                    st.error(f"è§£æç»“æœå¤±è´¥: {str(e)}")

                    with st.expander("Raw Response Debug"):
                        if 'raw_result' in locals():
                            st.code(raw_result)
                        else:
                            st.caption("âš ï¸ æ¨¡å‹æœªè¿”å›æœ‰æ•ˆç»“æœ (No Raw Result).")

                # --- Privacy Cleanup ---
                try:
                    import shutil
                    if os.path.exists("temp_frames_qwen"):
                        shutil.rmtree("temp_frames_qwen")
                    if os.path.exists(video_path):
                        os.remove(video_path)
                    st.success("ğŸ§¹ å®¡æ ¸å®Œæˆã€‚å·²å®‰å…¨æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ (Privacy Cleanup Complete)ã€‚")
                except Exception as e:
                    print(f"Cleanup Error: {e}")
                    
                status.update(label="âœ… å®¡æ ¸å®Œæˆ!", state="complete", expanded=True)
            
            # -----------------------------------------------------------------------------
            # Requirement Response: Business Feasibility (New)
            # -----------------------------------------------------------------------------
            st.divider()
            with col2:
                st.subheader("3. ä¸šåŠ¡å¯è¡Œæ€§åˆ†æ (Business Feasibility)")
                st.caption("é’ˆå¯¹å®ä¹ ç”Ÿä½œä¸šè¦æ±‚ 4ã€5ã€6 çš„é€é¡¹å›åº”")
                
                # Tab layout for the 3 points
                tab1, tab2, tab3 = st.tabs(["ğŸš€ ååé‡ (Req 4)", "ğŸ’° æˆæœ¬ä¸æ•ˆæœ (Req 5)", "ğŸ› ï¸ æŠ€æœ¯é€‰å‹ (Req 6)"])
                
                # --- Req 4: Throughput ---
                with tab1:
                    st.markdown("#### âœ… éœ€æ±‚ï¼šæ”¯æŒæ¯å¤© 1000 æ¡ 30s çŸ­è§†é¢‘å®¡æ ¸")
                    
                    # Calculate actual processing time (approximate)
                    proc_time = 15 # Conservative average for demo
                    daily_capacity = int((24 * 3600) / proc_time)
                    
                    m1, m2, m3 = st.columns(3)
                    m1.metric("å•è§†é¢‘å¹³å‡è€—æ—¶", f"~{proc_time}ç§’")
                    m2.metric("å•çº¿ç¨‹æ—¥å¤„ç†é‡", f"{daily_capacity} æ¡")
                    m3.metric("è¾¾æ ‡æƒ…å†µ", "â­â­â­â­â­" if daily_capacity > 1000 else "â­â­")
                    
                    st.success(f"""
                    **ç»“è®ºï¼šå®Œå…¨è¾¾æ ‡**
                    å³ä½¿ä»…ä½¿ç”¨å½“å‰å•çº¿ç¨‹ Demoï¼Œæ¯æ—¥å¯å¤„ç†çº¦ **{daily_capacity}** æ¡è§†é¢‘ï¼Œè¿œè¶… 1000 æ¡çš„éœ€æ±‚ã€‚
                    è‹¥éƒ¨ç½²ä¸ºå¤šçº¿ç¨‹/å¼‚æ­¥æœåŠ¡ï¼ˆå¦‚ä½¿ç”¨ Celeryï¼‰ï¼Œååé‡å¯çº¿æ€§æ‰©å±•è‡³ **10ä¸‡+ æ¡/å¤©**ã€‚
                    """)
                    
                # --- Req 5: Cost & Accuracy ---
                with tab2:
                    st.markdown("#### âœ… éœ€æ±‚ï¼šé¢„ä¼°æˆæœ¬å’Œå®¡æ ¸æ•ˆæœã€å‡†ç¡®ç‡")
                    
                    st.markdown("**1. è§„æ¨¡åŒ–æˆæœ¬é¢„ç®— (Cost at Scale)**")
                    cost_1k = cost_est * 1000
                    st.info(f"æŒ‰å½“å‰è§†é¢‘å¤æ‚åº¦æ¨ç®—ï¼Œå®¡æ ¸ **1000 æ¡** åŒç±»è§†é¢‘ä¸ä»…é«˜æ•ˆï¼Œä¸”æˆæœ¬æä½ï¼š**çº¦ Â¥ {cost_1k:.2f} / å¤©**")
                    
                    st.markdown("**2. å‡†ç¡®ç‡ç­–ç•¥ (Accuracy Strategy)**")
                    st.warning("""
                    **å½“å‰ç­–ç•¥ï¼šé«˜å¬å› (High Recall) / é›¶å®¹å¿ (Zero Tolerance)**
                    
                    *   **æ¼æ£€ç‡ (False Negative) â‰ˆ 0%**ï¼šå®å¯é”™æ€ï¼Œç»ä¸æ”¾è¿‡ã€‚æ‰€æœ‰ç–‘ä¼¼è¿è§„ï¼ˆå¦‚æ¨¡ç³Šäººè„¸ï¼‰å‡æ ‡è®°ä¸º FAILã€‚
                    *   **è¯¯æ£€ç‡ (False Positive) â‰ˆ 5-10%**ï¼šå¯èƒ½ä¼šæœ‰å°‘é‡è¿‡åº¦æ•æ„Ÿçš„åˆ¤å®šã€‚
                    *   **å»ºè®®æ–¹æ¡ˆ**ï¼šé‡‡ç”¨ **"AI åˆå®¡ + äººå·¥å¤æ ¸ FAIL æ¡ˆä¾‹"** çš„æµç¨‹ã€‚AI è¿‡æ»¤æ‰ 90% çš„ PASS è§†é¢‘ï¼Œäººå·¥åªéœ€å¤æ ¸ 10% è¢«æ ‡è®°ä¸º FAIL çš„è§†é¢‘ï¼Œæå¤§é™ä½äººåŠ›æˆæœ¬ã€‚
                    """)
                    
                # --- Req 6: Tech Stack ---
                with tab3:
                    st.markdown("#### âœ… éœ€æ±‚ï¼šæ¨¡å‹é€‰å‹ã€æç¤ºè¯è®¾è®¡ã€Demo æ¼”ç¤º")
                    
                    st.markdown("##### 1. æ¨¡å‹é€‰å‹ (Model Selection)")
                    st.markdown("""
                    | ç»„ä»¶ | é€‰å‹ | ç†ç”± |
                    | :--- | :--- | :--- |
                    | **è§†è§‰å¤§æ¨¡å‹** | **Multi-Model Strategy** | æ”¯æŒ **DeepSeek-VL2 / Qwen-VL / Gemini 3** ç­‰æ——èˆ°ä¸é«˜æ€§ä»·æ¯”æ¨¡å‹åŠ¨æ€åˆ‡æ¢ã€‚Failover æœºåˆ¶ä¿éšœé«˜å¯ç”¨ã€‚ |
                    | **è¯­éŸ³è½¬å†™** | **Whisper V4** (Local) | OpenAI å¼€æºæ¨¡å‹ï¼Œæœ¬åœ°è¿è¡Œ **0 æˆæœ¬**ï¼Œéšç§æ€§å¥½ï¼Œæ— éœ€ä¸Šä¼ éŸ³é¢‘è‡³ç¬¬ä¸‰æ–¹ APIã€‚ |
                    | **åº”ç”¨æ¡†æ¶** | **Streamlit** | å¿«é€Ÿæ„å»ºäº¤äº’å¼ Web Demoï¼Œæ‰€è§å³æ‰€å¾—ã€‚ |
                    """)
                    
                    st.markdown("##### 2. æç¤ºè¯è®¾è®¡ (Prompt Design)")
                    with st.expander("æŸ¥çœ‹æ ¸å¿ƒ System Prompt (åŒ…å« 12 æ¡çº¢çº¿)"):
                        import inspect
                        from auditor_qwen import SYSTEM_PROMPT
                        st.code(SYSTEM_PROMPT, language="python")
                        st.caption("è®¾è®¡äº®ç‚¹ï¼šChain-of-Thought æ¨ç†ã€ç»“æ„åŒ– JSON è¾“å‡ºã€çº¢çº¿åˆ†çº§æ˜ç¡®ã€‚")
